{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "A11-TextMining.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cq8gVnPmjAaF"
      },
      "source": [
        "##Import Libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oIqWZ8y1C3nV"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import nltk\n",
        "import spacy\n",
        "from nltk.corpus import stopwords"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2DyuuAfMjM_H"
      },
      "source": [
        "##Positive Word List\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HhrG8ofbjM7g"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9AJCximcDYoL"
      },
      "source": [
        "positive=pd.read_csv('positive-words.txt',sep='\\n',  encoding='cp1252',header=None)\n",
        "positive.iloc[30:40,:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OKIrcZ6zDYrU"
      },
      "source": [
        "positive[positive[0]=='a+'].index.values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I23KlFnNDYyD"
      },
      "source": [
        "positive.drop(range(0,35),axis=0,inplace=True)\n",
        "positive.reset_index(inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ThULVwXHG1LJ"
      },
      "source": [
        "positive.drop(labels=['index'],axis=1,inplace=True)\n",
        "positive.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wlUGK2E5G1GB"
      },
      "source": [
        "positive['Value']=np.ones(shape=(positive.shape[0]),dtype=int)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Enth6tlzG1Cf"
      },
      "source": [
        "positive"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9b9tSE0aH_UG"
      },
      "source": [
        "##Negative Word List"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NwI0ADbYG0-k"
      },
      "source": [
        "negative=pd.read_csv('negative-words.txt',sep='\\n',  encoding='cp1252',header=None , )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "syxWwVPlG01h"
      },
      "source": [
        "negative.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZ4lJigjG0vS"
      },
      "source": [
        "negative[negative[0]=='2-faces'].index.values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFaZ3nhIIyMw"
      },
      "source": [
        "negative.drop(range(0,36),axis=0,inplace=True)\n",
        "negative.reset_index(inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w6iBavqhIyJo"
      },
      "source": [
        "negative.drop(labels=['index'],axis=1,inplace=True)\n",
        "negative.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KpkfavxzIyGU"
      },
      "source": [
        "negative['Value']=[-1 for i in range(0,negative.shape[0])]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DkQsL1f_IyC4"
      },
      "source": [
        "negative"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1qwg_fruJWiM"
      },
      "source": [
        "##Combining Both the List\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E5sic_eiIx_O"
      },
      "source": [
        "all_words = negative.append(positive)\n",
        "all_words"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0kfitYhFJlQC"
      },
      "source": [
        "##Stop Words\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MI8kMj2gKCKP"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gfbd_uu5JwIW"
      },
      "source": [
        "stop1=stopwords.words('english')\n",
        "list(stop1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "khBv4pqZJxpX"
      },
      "source": [
        "stop2=pd.read_csv('stop.txt',sep='\\n',  encoding='cp1252',header=None)\n",
        "stop2=np.array(stop2).flatten()\n",
        "stop2=list(stop2)\n",
        "stop2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZkG_RIlRJxeH"
      },
      "source": [
        "stop=stop1+stop2\n",
        "print(len(stop))\n",
        "stop3=set(stop)\n",
        "print(len(stop3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bakh3EhhKAWP"
      },
      "source": [
        "##ElonMusk Tweet\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gtqvMfW-J54u"
      },
      "source": [
        "df=pd.read_csv('Elon_musk.csv', encoding='cp1252')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9LqFN4s8J50S"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "18GiKHTMJ5uv"
      },
      "source": [
        "df.rename(columns={'Unnamed: 0': 'Index'},inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0jJJafcXKhin"
      },
      "source": [
        "df.drop(labels=['Index'],axis=1,inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6mpFgncCKhfR"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RhasfLGBXyZW"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dzvQScLkXy2Y"
      },
      "source": [
        "df = [Text.strip() for Text in df.Text] # remove both the leading and the trailing characters\n",
        "df = [Text for Text in df if Text] # removes empty strings, because they are considered in Python as False\n",
        "df[0:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8YemfMRxXySp"
      },
      "source": [
        "text = ' '.join(df)\n",
        "text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WfshE8QVKoZW"
      },
      "source": [
        "##Text Preprocessing "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1aUmvN7CTBsC"
      },
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import string # special operations on strings\n",
        "import spacy # language models\n",
        "\n",
        "from matplotlib.pyplot import imread\n",
        "from matplotlib import pyplot as plt\n",
        "from wordcloud import WordCloud\n",
        "%matplotlib inline\n",
        "\n",
        "import warnings\n",
        "import re\n",
        "import string\n",
        "import nltk"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b133Lm-HTVQq"
      },
      "source": [
        "no_punc_text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "no_punc_text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TAHiZSiGQw7n"
      },
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "from nltk.tokenize import word_tokenize\n",
        "text_tokens = word_tokenize(no_punc_text)\n",
        "print(text_tokens[0:50])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EPu0K7ViQ_jZ"
      },
      "source": [
        "len(text_tokens)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wskEJzcQRErx"
      },
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "my_stop_words = stopwords.words('english')\n",
        "my_stop_words.append('the')\n",
        "no_stop_tokens = [word for word in text_tokens if not word in my_stop_words]\n",
        "print(no_stop_tokens[0:40])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gHXkefU7RIWO"
      },
      "source": [
        "lower_words = [Text.lower() for Text in no_stop_tokens]\n",
        "print(lower_words[0:25])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QHQ-DlLFRMbC"
      },
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "ps = PorterStemmer()\n",
        "stemmed_tokens = [ps.stem(word) for word in lower_words]\n",
        "print(stemmed_tokens[0:40])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ksqTiJIeRRES"
      },
      "source": [
        "nlp = spacy.load('en_core_web_sm')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WhQTl1IfYYRg"
      },
      "source": [
        "doc = nlp(' '.join(no_stop_tokens))\n",
        "print(doc[0:40])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uf-IrmXNRXBP"
      },
      "source": [
        "lemmas = [token.lemma_ for token in doc]\n",
        "print(lemmas[0:25])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_qkOyPDsRbhd"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "vectorizer = CountVectorizer()\n",
        "X = vectorizer.fit_transform(lemmas)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4JYxgjvyRbda"
      },
      "source": [
        "print(vectorizer.vocabulary_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dfw-TGwERnbx"
      },
      "source": [
        "print(X.toarray().shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QkekTz69Y29v"
      },
      "source": [
        "print(vectorizer.get_feature_names()[50:100])\n",
        "print(X.toarray()[50:100])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "18Z7StK_Y24k"
      },
      "source": [
        "print(X.toarray().shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fgTs6WTERnYR"
      },
      "source": [
        "vectorizer_ngram_range = CountVectorizer(analyzer='word',ngram_range=(1,3),max_features = 100)\n",
        "bow_matrix_ngram =vectorizer_ngram_range.fit_transform(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m37YoSInRnVo"
      },
      "source": [
        "print(vectorizer_ngram_range.get_feature_names())\n",
        "print(bow_matrix_ngram.toarray())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "POUAgbv1RnRY"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "vectorizer_n_gram_max_features = TfidfVectorizer(norm=\"l2\",analyzer='word', ngram_range=(1,3), max_features = 500)\n",
        "tf_idf_matrix_n_gram_max_features =vectorizer_n_gram_max_features.fit_transform(df)\n",
        "print(vectorizer_n_gram_max_features.get_feature_names())\n",
        "print(tf_idf_matrix_n_gram_max_features.toarray())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ng0NrMLKRnN9"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from wordcloud import WordCloud, STOPWORDS\n",
        "# Define a function to plot word cloud\n",
        "def plot_cloud(wordcloud):\n",
        "    # Set figure size\n",
        "    plt.figure(figsize=(40, 30))\n",
        "    # Display image\n",
        "    plt.imshow(wordcloud) \n",
        "    # No axis details\n",
        "    plt.axis(\"off\");"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uSVy5gRBRnKQ"
      },
      "source": [
        "stopwords = STOPWORDS\n",
        "stopwords.add('will')\n",
        "wordcloud = WordCloud(width = 3000, height = 2000, background_color='black', max_words=100,colormap='Set2',stopwords=stopwords).generate(text)\n",
        "# Plot\n",
        "plot_cloud(wordcloud)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aPE7tngxLkfr"
      },
      "source": [
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "doc_block = nlp(text)\n",
        "spacy.displacy.render(doc_block, style='ent', jupyter=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eByP2NgQLkbQ"
      },
      "source": [
        "all_scores = all_words.set_index(0)['Value'].to_dict()\n",
        "all_scores"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sLPL41f0MYQW"
      },
      "source": [
        "nlp = spacy.load('en_core_web_sm')\n",
        "sentiment_lexicon = all_scores\n",
        "\n",
        "def calculate_sentiment(text: str = None):\n",
        "    sent_score = 0\n",
        "    if text:\n",
        "        sentence = nlp(text)\n",
        "        for word in sentence:\n",
        "            sent_score += sentiment_lexicon.get(word.lemma_, 0)\n",
        "    return sent_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tvkZYpgCMyGf"
      },
      "source": [
        "calculate_sentiment(text = 'amazing')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P5dCk5_nalxs"
      },
      "source": [
        "from nltk import tokenize\n",
        "sentences=tokenize.sent_tokenize(' '.join(text))\n",
        "sentences"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qsphf-YJaEr_"
      },
      "source": [
        "sent_df=pd.DataFrame(sentences,columns=['sentence'])\n",
        "sent_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N6OeKH9PMyC1"
      },
      "source": [
        "sent_df['sentiment_value']=sent_df['sentence'].apply(calculate_sentiment)\n",
        "sent_df['sentiment_value']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2OOMl7xFMx_K"
      },
      "source": [
        "sent_df['word_count']=sent_df['sentence'].str.split().apply(len)\n",
        "sent_df['word_count']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gJa5l52NMx6u"
      },
      "source": [
        "sent_df.sort_values(by='sentiment_value')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jVKAgoqyNG-0"
      },
      "source": [
        "sent_df.sort_values(by='sentiment_value')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pGlli7v-NG77"
      },
      "source": [
        "# Sentiment score of the whole review\n",
        "sent_df['sentiment_value'].describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-RmJoLYNG4r"
      },
      "source": [
        "# negative sentiment score of the whole review\n",
        "sent_df[sent_df['sentiment_value']<=0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0svXH2mkNG1p"
      },
      "source": [
        "# positive sentiment score of the whole review\n",
        "sent_df[sent_df['sentiment_value']>0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XzjvL6DcNGxx"
      },
      "source": [
        "# Adding index cloumn\n",
        "sent_df['index']=range(0,len(sent_df))\n",
        "sent_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z6AHdTTbNcMs"
      },
      "source": [
        "# Plotting the sentiment value for whole review\n",
        "import seaborn as sns\n",
        "plt.figure(figsize=(15,10))\n",
        "sns.distplot(sent_df['sentiment_value'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pUFay3JMMEf6"
      },
      "source": [
        "# Plotting the line plot for sentiment value of whole review\n",
        "plt.figure(figsize=(15,10))\n",
        "sns.lineplot(y='sentiment_value',x='index',data=sent_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0AQGaP4uMEYV"
      },
      "source": [
        "# Correlation analysis\n",
        "sent_df.plot.scatter(x='word_count',y='sentiment_value',figsize=(8,8),title='Sentence sentiment value to sentence word count')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FDAKtjx0cTob"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}